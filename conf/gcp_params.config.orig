/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    GCP-specific parameters for bacterial genomics SNP pipeline
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

params {
    /*
    ============================================
        Google Cloud Platform Settings
    ============================================
    */
    
    // GCP Project and Region
    gcp_project                       = null  // Set via --gcp_project or GOOGLE_CLOUD_PROJECT env var
    gcp_region                        = 'us-central1'
    gcp_zone                          = 'us-central1-a'
    
    // Google Cloud Storage settings
    gcs_input_bucket                  = null  // e.g., 'gs://my-bucket/input-data/'
    gcs_output_bucket                 = null  // e.g., 'gs://my-bucket/results/'
    gcs_work_bucket                   = null  // e.g., 'gs://my-bucket/work/' (optional)
    
    /*
    ============================================
        Resource Optimization Parameters
    ============================================
    */
    
    // Gubbins optimization parameters
    gubbins_cpus                      = 4
    gubbins_memory                    = '16 GB'
    gubbins_time                      = '6 h'
    gubbins_iterations                = 5      // Reduce for large datasets
    gubbins_model_fitter              = 'fasttree'  // Options: fasttree, raxml, iqtree
    gubbins_filter_percentage         = 15     // Filter out sites with >X% gaps
    use_optimized_gubbins             = true   // Use the optimized Gubbins module
    
    // ParSNP optimization parameters
    parsnp_cpus                       = 4
    parsnp_memory                     = '8 GB'
    parsnp_args                       = ''     // Additional ParSNP arguments
    
    // Alternative recombination detection (faster than Gubbins)
    use_clonalframeml_instead         = false  // Use ClonalFrameML instead of Gubbins for speed
    
    /*
    ============================================
        Cost Optimization Settings
    ============================================
    */
    
    // Use preemptible instances (can be interrupted but much cheaper)
    use_preemptible                   = true
    
    // Automatic scaling based on input size
    auto_scale_resources              = true
    
    // Cost monitoring and alerts
    log_cost_estimates                = true
    max_estimated_cost                = 100.0  // USD, workflow will warn if exceeded
    estimated_genome_count            = 100    // Help with cost estimation
    
    /*
    ============================================
        Debugging and Monitoring
    ============================================
    */
    
    // Enhanced logging
    debug_mode                        = false
    verbose_logging                   = true
    log_system_resources              = true
    
    // Performance monitoring
    monitor_resource_usage            = true
    generate_performance_report       = true
    
    // Error handling
    aggressive_retry                  = true   // More retries for transient cloud errors
    fail_fast_on_critical_errors      = false // Continue with partial results when possible
    
    /*
    ============================================
        Data Management
    ============================================
    */
    
    // Staging and cleanup
    stage_in_copies                   = false  // Use symlinks when possible to save space
    cleanup_work_dir                  = true   // Clean up intermediate files
    compress_outputs                  = false  // Compress output files (slower but saves storage)
    
    // Batch processing optimization
    batch_size                        = 50     // Process files in batches for efficiency
    parallel_uploads                  = 4      // Parallel uploads to GCS
    
    /*
    ============================================
        Quality Control Thresholds
    ============================================
    */
    
    // Adaptive QC based on dataset size
    min_input_filesize_large          = "100k"  // For datasets >200 genomes
    min_input_filesize_medium         = "50k"   // For datasets 50-200 genomes
    min_input_filesize_small          = "10k"   // For datasets <50 genomes
    
    /*
    ============================================
        Workflow Optimization
    ============================================
    */
    
    // Skip computationally expensive steps for large datasets
    skip_recombination_large_datasets = false  // Skip recombination detection for >500 genomes
    large_dataset_threshold           = 500     // Number of genomes considered "large"
    
    // Use faster alternatives
    use_fast_tree_only                = false  // Skip RAxML, use only FastTree
    skip_excel_outputs                = true   // Skip Excel generation to save time
    
    /*
    ============================================
        Google Batch Configuration
    ============================================
    */
    
    // Work directory (Google Cloud Storage bucket)
    gcp_work_dir                      = null  // e.g., 'gs://your-bucket/nextflow_work'
    
    // Batch volumes for mounting GCS buckets
    batch_volumes                     = []     // e.g., ['gs://your-bucket/': '/mnt/gcs']
    
    // Boot disk configuration
    boot_disk_size                    = '20 GB'
    disk_type                         = 'pd-standard'  // pd-standard, pd-ssd, pd-balanced
    
    // CPU platform (optional)
    cpu_platform                      = null   // e.g., 'Intel Skylake'
    
    /*
    ============================================
        Advanced GCP Features
    ============================================
    */
    
    // Custom service account
    gcp_service_account               = null
    
    // Network configuration
    gcp_network                       = 'default'
    gcp_subnetwork                    = null
    use_private_address               = false
    
    // GCP labels for resource tracking
    gcp_labels                        = '--labels=workflow=bacterial-genomics,env=prod'
}